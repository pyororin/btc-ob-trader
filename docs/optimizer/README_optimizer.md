# `optimizer` サービス 詳細設計書

## 1. サービスの概要

`optimizer`サービスは、取引戦略のパラメータを自動的に最適化する心臓部です。Python製の最適化フレームワーク`Optuna`を利用して、過去の市場データに対するバックテストを数千回繰り返し、最も収益性が高く、かつ頑健（ロバスト）なパラメータの組み合わせを発見します。

最終的に見つけ出した最適なパラメータ設定を`trade_config.yaml`ファイルとして出力し、`bot`サービスが実際の取引で利用できるようにします。

## 2. Docker Compose上の役割と設定

`docker-compose.yml`における`optimizer`サービスの定義は以下の通りです。

```yaml
services:
  optimizer:
    build:
      context: .
      dockerfile: optimizer/Dockerfile
    container_name: obi-scalp-optimizer
    command: python optimizer/optimizer.py
    healthcheck:
      test: ["CMD-SHELL", "test -f /data/params/trade_config.yaml"]
      # ...
    restart: always
    # ...
```

### 設定解説

-   **`build`**: `optimizer/Dockerfile`を使用してPython環境と必要なライブラリ（`optuna`, `sqlalchemy`など）をセットアップします。
-   **`command`**: コンテナ起動時に`optimizer/optimizer.py`スクリプトを実行します。
-   **`volumes`**:
    -   `./data/params:/data/params`: 最適化結果である`trade_config.yaml`や、Optunaの学習履歴DB（`optuna_study.db`）を永続化し、`bot`サービスと共有するためにマウントします。
-   **`healthcheck`**: `/data/params/trade_config.yaml`ファイルが存在するかどうかをチェックします。このファイルは最適化が成功した場合にのみ生成されるため、このヘルスチェックが通ることは、有効な取引パラメータが準備できたことを意味します。`bot`サービスはこのヘルスチェックの成功を待ってから起動します。
-   **`restart: always`**: スクリプトが一度完了（またはエラーで終了）しても、常に再起動します。これにより、定期的な再最適化サイクルを実現しています。

## 3. 処理フローとロジック

`optimizer.py`の処理は、大きく分けて以下のステップで構成されます。

### 3.1. ジョブの待機

-   サービスは起動後、`./data/params/optimization_job.json` ファイルが出現するのを待ち続けます。このJSONファイルが、最適化プロセスの開始を指示するトリガーとなります。（通常は `drift-monitor` サービスによって作成されます）

### 3.2. データ準備 (Walk-Forward分析の準備)

1.  **データのエクスポート**: `go run cmd/export/main.go` を内部で実行し、`timescaledb`から指定された期間の市場データ（注文簿、取引履歴）をCSVファイルとしてエクスポートします。
2.  **データ分割**: エクスポートしたデータを2つに分割します。
    -   **In-Sample (IS) データ**: 期間の前半部分。パラメータの探索と学習（最適化）に使用します。
    -   **Out-of-Sample (OOS) データ**: 期間の後半部分。ISデータで学習したパラメータが、未知のデータに対しても通用するかを検証するために使用します。

### 3.3. In-Sample (IS) 最適化 (Optunaによる探索)

1.  **最適化セッション (Study) の開始**: `Optuna`の`Study`オブジェクトを生成します。
2.  **試行 (Trial) の繰り返し**: `config/optimizer_config.yaml`で設定された`n_trials`回数（例: 2000回）、以下の`objective`関数を実行します。
    -   **パラメータ生成**: `trial.suggest_*`を使い、探索範囲内でランダムなパラメータの組み合わせを生成します。
    -   **バックテスト実行**: 生成したパラメータで`trade_config.yaml`を一時的に作成し、`botsimulate`のロジック（`go run cmd/bot/main.go --simulate`）を呼び出してISデータ上でバックテストを実行します。
    -   **評価と枝刈り (Pruning)**: バックテスト結果からシャープレシオや取引回数を取得します。取引回数が極端に少ないなど、明らかに性能が悪い試行は、計算を途中で打ち切って（枝刈りして）効率化します。
    -   **スコアの記録**: バックテストの評価スコア（シャープレシオ）をOptunaに記録します。

### 3.4. 最適化結果の分析と候補選定

1.  **複合スコアによる再評価**: 全ての試行完了後、単一の指標（シャープレシオ）だけでなく、プロフィットファクター、最大ドローダウン、取引回数などを重み付けした独自の複合スコアで全試行をランク付けし直し、最もバランスの取れたパラメータを探します。
2.  **頑健性分析**: `analyzer.py`を呼び出し、上位の試行結果からパラメータの分布を分析し、特定の狭い範囲だけでなく、広い範囲で安定して良好な性能を示す「頑健な」パラメータセットを特定します。

### 3.5. Out-of-Sample (OOS) 検証 (ウォークフォワード検証)

1.  **検証の実行**: IS最適化で選ばれた最良のパラメータ候補を使い、今度は未知のデータであるOOSデータでバックテストを実行します。
2.  **合格判定**: OOSでのバックテスト結果が、`config/optimizer_config.yaml`で定義された最低基準（`oos_min_profit_factor >= 1.2`など）を満たしているか判定します。
3.  **最終パラメータの決定**:
    -   **合格した場合**: そのパラメータは信頼できると判断し、最終的な`trade_config.yaml`として出力します。
    -   **不合格だった場合**: 2番目に良かった候補で再度OOS検証を試みます。これを`max_retry`回繰り返します。
    -   **全滅した場合**: 有効なパラメータが見つからなかったと判断し、`trade_config.yaml`は更新されません。

### 3.6. 完了と待機

-   `optimization_job.json`を削除し、一連の最適化サイクルを完了します。その後、再び次のジョブファイルが出現するのを待ちます。

## 4. 設計思想と考慮点

-   **自動化されたWalk-Forward最適化**: データセットをISとOOSに分割し、「学習」と「検証」を分離するウォークフォワード最適化の手法を自動化しています。これにより、過去のデータに過剰に適合（カーブフィッティング）してしまうことを防ぎ、未来の未知の相場に対する汎用性を高めています。
-   **頑健性の重視**: 単にIS期間で最も高いスコアを出したパラメータを選ぶのではなく、複合スコアでの再評価や`analyzer.py`による分析を通じて、より安定し、信頼できるパラメータを選ぼうとします。
-   **効率的な探索**: Optunaの高度なサンプリングアルゴリズム（`CmaEsSampler`）と枝刈り機能（`HyperbandPruner`）を活用し、広大なパラメータ空間から効率的に有望な解を見つけ出します。
-   **回復力と継続性**: `restart: always`とジョブファイル駆動のアーキテクチャにより、定期的に市場の変化をキャッチアップし、戦略を自己修正し続ける自律的な最適化ループを実現しています。

## 5. 想定ユースケースとトリガー

-   **ユースケース**: 市場の状況（ボラティリティ、流動性など）の変化に適応するため、取引戦略のパラメータを定期的に見直し、常に最適な状態で取引を行えるようにする。
-   **トリガー**: `drift-monitor`サービスが市場の変化を検知し、`optimization_job.json`ファイルを作成することによって、本サービスの最適化プロセスが起動されます。
